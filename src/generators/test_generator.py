"""Test Generator - Generates automated tests for generated code."""
import sys
from pathlib import Path
from typing import Dict, Any, List, Optional
import json

# Add project root to path
project_root = Path(__file__).parent.parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))
if str(project_root / "src") not in sys.path:
    sys.path.insert(0, str(project_root / "src"))

from utils.logger import get_logger

logger = get_logger(__name__)


class TestGenerator:
    """Generates automated tests for generated code."""
    
    def __init__(self):
        """Initialize test generator."""
        logger.info("TestGenerator initialized")
    
    def generate_pyspark_tests(self,
                              canonical_model: Dict[str, Any],
                              generated_code: str,
                              test_data: Optional[List[Dict[str, Any]]] = None) -> str:
        """Generate pytest tests for PySpark code.
        
        Args:
            canonical_model: Canonical model
            generated_code: Generated PySpark code
            test_data: Optional test data
            
        Returns:
            Generated test code string
        """
        logger.info("Generating PySpark tests")
        
        mapping_name = canonical_model.get('mapping_name', 'unknown_mapping')
        test_class_name = f"Test{self._to_pascal_case(mapping_name)}"
        
        # Generate test data if not provided
        if not test_data:
            test_data = self._generate_test_data(canonical_model)
        
        # Generate test code
        test_code = f'''"""
Automated tests for {mapping_name} mapping.
Generated by Informatica Modernization Accelerator.
"""
import pytest
from pyspark.sql import SparkSession
from pyspark.sql.types import *
from pyspark.sql.functions import col, lit
import sys
from pathlib import Path

# Add generated code to path
sys.path.insert(0, str(Path(__file__).parent))

# Import the generated mapping function
from {mapping_name.lower().replace('m_', '')} import *


class {test_class_name}:
    """Test suite for {mapping_name}."""
    
    @pytest.fixture(scope="class")
    def spark(self):
        """Create Spark session for testing."""
        return SparkSession.builder \\
            .appName("test_{mapping_name}") \\
            .master("local[2]") \\
            .config("spark.sql.warehouse.dir", "/tmp/spark-warehouse") \\
            .getOrCreate()
    
    @pytest.fixture(scope="class")
    def test_data(self, spark):
        """Create test DataFrame."""
        test_data = {json.dumps(test_data, indent=8)}
        return spark.createDataFrame(test_data)
    
    def test_schema_validation(self, spark, test_data):
        """Test that output schema matches expected schema."""
        # Execute transformation
        result_df = transform_mapping(test_data)
        
        # Get expected schema from canonical model
        expected_fields = {self._get_expected_fields(canonical_model)}
        
        # Validate schema
        actual_schema = result_df.schema
        assert len(actual_schema.fields) == len(expected_fields), \\
            f"Schema field count mismatch: expected {{len(expected_fields)}}, got {{len(actual_schema.fields)}}"
        
        for field_name, field_type in expected_fields.items():
            field = next((f for f in actual_schema.fields if f.name == field_name), None)
            assert field is not None, f"Field {{field_name}} not found in output schema"
            # Type validation would go here
    
    def test_transformation_logic(self, spark, test_data):
        """Test transformation logic against test data."""
        # Execute transformation
        result_df = transform_mapping(test_data)
        
        # Collect results
        results = result_df.collect()
        
        # Validate results
        assert len(results) == len(test_data), \\
            f"Row count mismatch: expected {{len(test_data)}}, got {{len(results)}}"
        
        # Validate specific transformations
        {self._generate_transformation_assertions(canonical_model)}
    
    def test_null_handling(self, spark):
        """Test null value handling."""
        # Create test data with nulls
        null_test_data = {self._generate_null_test_data(canonical_model)}
        null_df = spark.createDataFrame(null_test_data)
        
        # Execute transformation
        result_df = transform_mapping(null_df)
        
        # Validate null handling
        results = result_df.collect()
        assert len(results) > 0, "No results returned for null test data"
    
    def test_data_quality(self, spark, test_data):
        """Test data quality rules."""
        # Execute transformation
        result_df = transform_mapping(test_data)
        
        # Check for nulls in key fields
        {self._generate_quality_checks(canonical_model)}


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
'''
        
        return test_code
    
    def generate_sql_tests(self,
                          canonical_model: Dict[str, Any],
                          generated_sql: str,
                          test_data: Optional[List[Dict[str, Any]]] = None) -> str:
        """Generate tests for SQL code.
        
        Args:
            canonical_model: Canonical model
            generated_sql: Generated SQL code
            test_data: Optional test data
            
        Returns:
            Generated test code string
        """
        logger.info("Generating SQL tests")
        
        mapping_name = canonical_model.get('mapping_name', 'unknown_mapping')
        
        # Generate test data if not provided
        if not test_data:
            test_data = self._generate_test_data(canonical_model)
        
        test_code = f'''"""
Automated tests for {mapping_name} SQL mapping.
Generated by Informatica Modernization Accelerator.
"""
import pytest
from pyspark.sql import SparkSession


class Test{mapping_name}SQL:
    """Test suite for {mapping_name} SQL."""
    
    @pytest.fixture(scope="class")
    def spark(self):
        """Create Spark session for testing."""
        return SparkSession.builder \\
            .appName("test_{mapping_name}_sql") \\
            .master("local[2]") \\
            .config("spark.sql.warehouse.dir", "/tmp/spark-warehouse") \\
            .getOrCreate()
    
    @pytest.fixture(scope="class")
    def test_data(self, spark):
        """Create test tables."""
        test_data = {json.dumps(test_data, indent=8)}
        df = spark.createDataFrame(test_data)
        df.createOrReplaceTempView("test_source")
        return df
    
    def test_sql_execution(self, spark, test_data):
        """Test SQL execution."""
        sql_query = """
{self._escape_sql(generated_sql)}
"""
        
        result_df = spark.sql(sql_query)
        results = result_df.collect()
        
        assert len(results) > 0, "SQL query returned no results"
    
    def test_sql_syntax(self, spark):
        """Test SQL syntax validity."""
        sql_query = """
{self._escape_sql(generated_sql)}
"""
        
        # Try to parse SQL
        try:
            spark.sql(f"EXPLAIN {sql_query}")
        except Exception as e:
            pytest.fail(f"SQL syntax error: {{str(e)}}")
    
    def test_sql_results(self, spark, test_data):
        """Test SQL results against expected output."""
        sql_query = """
{self._escape_sql(generated_sql)}
"""
        
        result_df = spark.sql(sql_query)
        results = result_df.collect()
        
        # Validate row count
        assert len(results) == len(test_data), \\
            f"Row count mismatch: expected {{len(test_data)}}, got {{len(results)}}"


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
'''
        
        return test_code
    
    def generate_integration_tests(self,
                                  workflow_name: str,
                                  workflow_structure: Dict[str, Any],
                                  test_config: Optional[Dict[str, Any]] = None) -> str:
        """Generate integration tests for a workflow.
        
        Args:
            workflow_name: Name of the workflow
            workflow_structure: Workflow structure with mappings
            test_config: Optional test configuration
            
        Returns:
            Generated integration test code
        """
        logger.info(f"Generating integration tests for workflow: {workflow_name}")
        
        test_code = f'''"""
Integration tests for {workflow_name} workflow.
Generated by Informatica Modernization Accelerator.
"""
import pytest
from pyspark.sql import SparkSession
import time


class Test{workflow_name}Integration:
    """Integration test suite for {workflow_name}."""
    
    @pytest.fixture(scope="class")
    def spark(self):
        """Create Spark session for testing."""
        return SparkSession.builder \\
            .appName("test_{workflow_name}_integration") \\
            .master("local[2]") \\
            .config("spark.sql.warehouse.dir", "/tmp/spark-warehouse") \\
            .getOrCreate()
    
    def test_workflow_execution(self, spark):
        """Test end-to-end workflow execution."""
        # This would execute the full workflow
        # For now, it's a placeholder structure
        
        mappings = {[m.get('name') for m in workflow_structure.get('mappings', [])]}
        
        for mapping_name in mappings:
            # Execute each mapping
            # Validate intermediate results
            pass
        
        assert True, "Workflow execution completed"
    
    def test_workflow_dependencies(self, spark):
        """Test workflow dependency order."""
        # Validate that mappings execute in correct order
        # based on dependencies
        
        dependencies = {workflow_structure.get('dependencies', [])}
        
        # Validate dependency order
        assert len(dependencies) >= 0, "Dependencies validated"
    
    def test_workflow_performance(self, spark):
        """Test workflow performance."""
        start_time = time.time()
        
        # Execute workflow
        # (placeholder)
        
        execution_time = time.time() - start_time
        
        # Performance assertions
        max_execution_time = {test_config.get('max_execution_time', 300) if test_config else 300}
        assert execution_time < max_execution_time, \\
            f"Workflow execution time {{execution_time}}s exceeds maximum {{max_execution_time}}s"


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
'''
        
        return test_code
    
    def _generate_test_data(self, canonical_model: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Generate test data from canonical model.
        
        Args:
            canonical_model: Canonical model
            
        Returns:
            List of test data dictionaries
        """
        test_data = []
        
        # Get source fields
        sources = canonical_model.get('sources', [])
        if sources:
            source_fields = sources[0].get('fields', [])
            
            # Generate 3-5 test rows
            for i in range(3):
                row = {}
                for field in source_fields:
                    field_name = field.get('name', '')
                    field_type = field.get('type', 'string')
                    row[field_name] = self._generate_test_value(field_type, i)
                test_data.append(row)
        
        return test_data
    
    def _generate_test_value(self, field_type: str, index: int) -> Any:
        """Generate a test value based on field type.
        
        Args:
            field_type: Field type
            index: Row index
            
        Returns:
            Test value
        """
        type_lower = field_type.lower()
        
        if 'int' in type_lower or 'integer' in type_lower:
            return 100 + index * 10
        elif 'decimal' in type_lower or 'float' in type_lower or 'double' in type_lower:
            return 100.5 + index * 10.5
        elif 'date' in type_lower or 'timestamp' in type_lower:
            return f"2024-01-{1 + index:02d}"
        elif 'bool' in type_lower or 'boolean' in type_lower:
            return index % 2 == 0
        else:
            return f"test_value_{index}"
    
    def _generate_null_test_data(self, canonical_model: Dict[str, Any]) -> str:
        """Generate null test data."""
        sources = canonical_model.get('sources', [])
        if sources:
            source_fields = sources[0].get('fields', [])
            row = {field.get('name'): None for field in source_fields}
            return json.dumps([row], indent=8)
        return "[]"
    
    def _get_expected_fields(self, canonical_model: Dict[str, Any]) -> str:
        """Get expected fields from canonical model."""
        targets = canonical_model.get('targets', [])
        if targets:
            fields = targets[0].get('fields', [])
            field_dict = {f.get('name'): f.get('type', 'string') for f in fields}
            return json.dumps(field_dict, indent=8)
        return "{}"
    
    def _generate_transformation_assertions(self, canonical_model: Dict[str, Any]) -> str:
        """Generate transformation assertions."""
        transformations = canonical_model.get('transformations', [])
        assertions = []
        
        for trans in transformations[:3]:  # Limit to first 3
            target_field = trans.get('target_field', '')
            if target_field:
                assertions.append(f"        # Validate {target_field}")
                assertions.append(f"        # assert results[0]['{target_field}'] == expected_value")
        
        return "\n".join(assertions) if assertions else "        pass"
    
    def _generate_quality_checks(self, canonical_model: Dict[str, Any]) -> str:
        """Generate data quality checks."""
        targets = canonical_model.get('targets', [])
        if targets:
            key_fields = [f.get('name') for f in targets[0].get('fields', [])[:3]]
            checks = []
            for field in key_fields:
                checks.append(f"        null_count = result_df.filter(col('{field}').isNull()).count()")
                checks.append(f"        assert null_count == 0, f'Null values found in {field}'")
            return "\n".join(checks)
        return "        pass"
    
    def _escape_sql(self, sql: str) -> str:
        """Escape SQL for Python string."""
        return sql.replace('"""', '\\"\\"\\"')
    
    def _to_pascal_case(self, name: str) -> str:
        """Convert name to PascalCase."""
        parts = name.replace('_', ' ').replace('-', ' ').split()
        return ''.join(word.capitalize() for word in parts)

